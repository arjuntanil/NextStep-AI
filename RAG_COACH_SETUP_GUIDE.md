# RAG Coach Setup and Usage Guide

## Overview
RAG Coach is a new feature in NextStepAI that provides personalized career coaching using PDF documents (resumes, job descriptions, career guides) with Ollama's Mistral 7B Q4 model.

## âœ… What Was Implemented

### 1. Dependencies Installed
- âœ… `langchain-community` - For Ollama integration and PDF loading
- âœ… `ollama` - Python client for Ollama LLM
- âœ… `pypdf` - PDF document processing

### 2. Backend Integration (`backend_api.py`)
- âœ… Three new API endpoints:
  - `POST /rag-coach/upload` - Upload PDF documents
  - `POST /rag-coach/build-index` - Build FAISS vector store
  - `POST /rag-coach/query` - Ask career questions
  - `GET /rag-coach/status` - Check RAG Coach status
- âœ… Lazy initialization (doesn't affect startup or existing features)
- âœ… Comprehensive error handling with Ollama installation instructions

### 3. Frontend Integration (`app.py`)
- âœ… New "ğŸ§‘â€ğŸ’¼ RAG Coach" tab in Streamlit interface
- âœ… PDF upload widgets (resume + job description)
- âœ… Automatic index building after upload
- âœ… Query interface with source attribution
- âœ… Helpful error messages for missing Ollama

### 4. RAG Coach Module (`rag_coach.py`)
- âœ… Updated to use Mistral 7B Q4 (not gemma:2b)
- âœ… PyPDFLoader for document processing
- âœ… FAISS vector store with HuggingFace embeddings
- âœ… Graceful model detection
- âœ… Source document tracking

### 5. Documentation (`README.md`)
- âœ… Added RAG Coach to key features
- âœ… Added Ollama prerequisites
- âœ… Added installation instructions
- âœ… Added API endpoint documentation

## ğŸš€ Installation Steps

### Step 1: Install Ollama
```bash
# Download from https://ollama.ai and install

# After installation, verify:
ollama --version
```

### Step 2: Pull Mistral 7B Q4 Model
```bash
ollama pull mistral:7b-q4
```

This will download the 4-bit quantized Mistral 7B model (~4GB).

### Step 3: Verify Dependencies
Dependencies are already installed:
- langchain-community
- ollama
- pypdf

## ğŸ“– Usage Guide

### Starting the Application

**Terminal 1 - Backend:**
```powershell
E:/NextStepAI/career_coach/Scripts/python.exe -m uvicorn backend_api:app --host 127.0.0.1 --port 8000 --reload
```

**Terminal 2 - Frontend:**
```powershell
E:/NextStepAI/career_coach/Scripts/Activate.ps1
streamlit run app.py
```

### Using RAG Coach

1. **Navigate to RAG Coach Tab**
   - Open http://localhost:8501
   - Click on "ğŸ§‘â€ğŸ’¼ RAG Coach" tab

2. **Upload Documents**
   - Upload your resume PDF
   - Upload job description PDF (optional)
   - Click "ğŸ“¤ Upload Documents to RAG Coach"
   - Wait for index building to complete

3. **Ask Questions**
   - Type your career question in the text area
   - Example: "Based on my resume, what skills should I develop for the job I'm applying to?"
   - Click "ğŸš€ Get RAG Coach Answer"
   - View the AI-generated answer with source attribution

## ğŸ” Testing Without Ollama

If Ollama is not installed, the system will:
- âœ… Allow PDF uploads (this works without Ollama)
- âŒ Fail at index building with clear error message
- ğŸ“ Show installation instructions in the UI

**Example error message:**
```
âŒ Ollama LLM not available
ğŸ“ Ollama not available: [connection refused]

To fix this:
- 1. Install Ollama: https://ollama.ai/download
- 2. Start Ollama service
- 3. Pull the model: ollama pull mistral:7b-q4
- 4. Verify: ollama list
```

## âœ… Verification of Non-Breaking Changes

### Existing Features Tested
All existing features continue to work:

1. **Resume Analyzer** âœ…
   - Upload PDF/DOCX resumes
   - Skill extraction with Gemini LLM
   - Job recommendation with ML model
   - Live job scraping from LinkedIn
   - ATS layout feedback

2. **AI Career Advisor** âœ…
   - Fine-tuned GPT-2 model responses
   - Career path queries
   - Live job postings
   - Fallback to RAG system

3. **User History** âœ…
   - Authentication with Google OAuth
   - JWT tokens
   - History tracking

### How We Ensured No Breaking Changes

1. **Lazy Loading**
   - RAG Coach is only imported when `/rag-coach/build-index` is called
   - Zero impact on startup time or memory

2. **Separate Module**
   - `rag_coach.py` is completely independent
   - No modifications to existing imports or functions

3. **Dedicated Endpoints**
   - All RAG Coach endpoints use `/rag-coach/` prefix
   - No overlap with existing routes

4. **Independent State**
   - `rag_coach_instance` is a global variable
   - Doesn't interfere with existing model instances

5. **Backend Startup Test**
   ```
   âœ… Embedding model initialized
   âœ… Fine-tuned Career Advisor wrapper initialized
   âœ… Resume analysis models loaded
   âœ… Gemini LLM initialized
   âœ… Career Guide RAG chain created
   âœ… Job Search RAG chain created
   âœ… Application startup complete
   ```

## ğŸ”§ API Endpoints

### Upload PDFs
```http
POST /rag-coach/upload
Content-Type: multipart/form-data

files: [File, File, ...]
```

**Response:**
```json
{
  "message": "Successfully uploaded 2 file(s)",
  "files_uploaded": ["resume.pdf", "job_desc.pdf"]
}
```

### Build Index
```http
POST /rag-coach/build-index
```

**Response:**
```json
{
  "message": "RAG Coach index built successfully",
  "indexed_files": 2,
  "files": ["resume.pdf", "job_desc.pdf"]
}
```

### Query RAG Coach
```http
POST /rag-coach/query
Content-Type: application/json

{
  "question": "What skills should I develop?",
  "show_context": true
}
```

**Response:**
```json
{
  "answer": "Based on your resume...",
  "context_chunks": [
    {
      "content": "...",
      "source": "resume.pdf"
    }
  ],
  "sources": ["resume.pdf"]
}
```

### Check Status
```http
GET /rag-coach/status
```

**Response:**
```json
{
  "initialized": true,
  "vector_store_ready": true,
  "qa_chain_ready": true,
  "message": "RAG Coach is ready"
}
```

## ğŸ›¡ï¸ Security and Privacy

- **Local Processing**: Ollama runs locally, no data sent to external APIs
- **PDF Storage**: Uploaded PDFs stored in `./uploads/` directory
- **Vector Store**: FAISS index stored locally in `./rag_coach_index/`
- **Model Quantization**: 4-bit quantization (Q4) reduces model size and memory usage

## ğŸ“Š Technical Details

- **Embedding Model**: sentence-transformers/all-MiniLM-L6-v2 (same as existing RAG)
- **LLM**: Ollama Mistral 7B Q4 (~4GB, 4-bit quantization)
- **Vector Store**: FAISS with L2 distance
- **Chunk Size**: 1000 characters with 200 character overlap
- **Temperature**: 0.7 (balanced creativity and accuracy)
- **Context Window**: 2048 tokens

## â“ Troubleshooting

### Issue: "Ollama not available"
**Solution:**
1. Install Ollama from https://ollama.ai
2. Start Ollama service (usually automatic on Windows/Mac)
3. Pull the model: `ollama pull mistral:7b-q4`
4. Verify: `ollama list`

### Issue: "No PDF files found"
**Solution:**
Upload PDFs first using the "ğŸ“¤ Upload Documents" button

### Issue: "RAG Coach not initialized"
**Solution:**
Build the index using the "ğŸ“¤ Upload Documents" button (it automatically builds index after upload)

### Issue: Backend startup is slow
**Note:** This is normal! The first startup loads:
- HuggingFace embedding models
- Fine-tuned GPT-2 model (background)
- Gemini LLM
- ML pipelines
- FAISS indices

RAG Coach doesn't add any delay because it uses lazy loading.

## ğŸ“ Next Steps

1. **Install Ollama** - Download and install from https://ollama.ai
2. **Pull Mistral Model** - Run `ollama pull mistral:7b-q4`
3. **Test RAG Coach** - Upload a resume PDF and ask questions
4. **Explore Features** - Try different career questions
5. **Compare Outputs** - See how RAG Coach differs from AI Career Advisor

## ğŸ¯ Success Criteria

- âœ… Dependencies installed successfully
- âœ… Backend starts without errors
- âœ… All existing features still work
- âœ… RAG Coach tab visible in UI
- âœ… PDF upload works
- âœ… Clear error messages when Ollama is missing
- âœ… Documentation updated
- âœ… No breaking changes to existing code
