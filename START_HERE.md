# üéØ READY-TO-USE: Start Your Application with RAG Coach

## ‚úÖ Current Status

Based on your terminal output:
- ‚úÖ Ollama is INSTALLED (version 0.12.6)
- ‚è≥ Mistral model is DOWNLOADING (`mistral:7b-instruct-q4_K_M`)
- ‚úÖ All Python dependencies are installed
- ‚úÖ RAG Coach code is updated to auto-detect Ollama

## üöÄ ONE-COMMAND START (Use This!)

###Option 1: Automatic Script (Recommended)

Just run this Python script - it does EVERYTHING automatically:

```powershell
E:/NextStepAI/career_coach/Scripts/python.exe auto_setup_rag_coach.py
```

This script will:
- ‚úÖ Find Ollama automatically (no PATH needed)
- ‚úÖ Check if Mistral model is ready
- ‚úÖ Offer to download if missing
- ‚úÖ Test the connection
- ‚úÖ Give you exact commands to start

### Option 2: Direct Application Start

Once the model download completes, just start your app:

**Terminal 1 - Backend:**
```powershell
cd E:\NextStepAI
E:/NextStepAI/career_coach/Scripts/python.exe -m uvicorn backend_api:app --reload
```

**Terminal 2 - Frontend:**
```powershell
cd E:\NextStepAI
E:/NextStepAI/career_coach/Scripts/Activate.ps1
streamlit run app.py
```

That's it! The RAG Coach will work automatically.

## ‚ùì Why "ollama" Command Doesn't Work in CMD?

**Short Answer:** You're using CMD, not PowerShell. Ollama was installed for PowerShell.

**Long Answer:**
- Ollama IS installed at: `C:\Users\<Your Username>\AppData\Local\Programs\Ollama\ollama.exe`
- Windows PowerShell can find it (PATH is updated for PowerShell)
- CMD cannot find it (PATH not updated for CMD)
- **Solution:** Use PowerShell, OR use the Python script (which finds Ollama automatically)

## üéØ What I Did to Fix Everything

### 1. Made RAG Coach Find Ollama Automatically
Updated `rag_coach.py` to search for Ollama in these locations:
- `%LOCALAPPDATA%\Programs\Ollama\ollama.exe`
- `C:\Program Files\Ollama\ollama.exe`
- `C:\Users\<Username>\AppData\Local\Programs\Ollama\ollama.exe`

**Result:** RAG Coach works WITHOUT needing `ollama` in PATH!

### 2. Auto-Detect Mistral Models
RAG Coach now automatically detects which Mistral model you have:
- `mistral:7b-instruct` ‚úÖ
- `mistral:7b-instruct-q4_K_M` ‚úÖ (you're downloading this)
- `mistral:latest` ‚úÖ
- Any other Mistral variant ‚úÖ

**Result:** No manual configuration needed!

### 3. Created Auto-Setup Script
`auto_setup_rag_coach.py` does everything:
- Finds Ollama
- Checks models
- Offers to download if missing
- Tests connection
- Gives you start commands

**Result:** One command to set everything up!

## üìä What's Happening Right Now

Your PowerShell terminal shows:
```
ollama pull mistral:7b-instruct-q4_K_M
pulling manifest
pulling faf975975644:  12% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñè 536 MB/4.4 GB   53 MB/s   1m11s
```

**This means:**
- ‚úÖ Download is IN PROGRESS
- ‚è±Ô∏è  12% complete (536 MB out of 4.4 GB downloaded)
- ‚è≥ About 1 minute 11 seconds remaining
- üöÄ Speed: 53 MB/s

**What to do:** Wait for it to finish (you'll see "success")

## üéâ After Download Completes

### Step 1: Verify (Optional)
```powershell
E:/NextStepAI/career_coach/Scripts/python.exe auto_setup_rag_coach.py
```

### Step 2: Start Application
```powershell
# Backend
E:/NextStepAI/career_coach/Scripts/python.exe -m uvicorn backend_api:app --reload

# Frontend (new terminal)
cd E:\NextStepAI
E:/NextStepAI/career_coach/Scripts/Activate.ps1
streamlit run app.py
```

### Step 3: Use RAG Coach
1. Open: http://localhost:8501
2. Click: "üßë‚Äçüíº RAG Coach" tab
3. Upload: Resume PDF + Job Description PDF
4. Click: "üì§ Upload Documents to RAG Coach"
5. Ask: "What skills should I develop based on my resume?"
6. See: AI answer with source documents!

## üõ†Ô∏è Troubleshooting

### If model download is stuck:
Wait for current download to complete, then check:
```powershell
# Find ollama.exe
dir "$env:LOCALAPPDATA\Programs\Ollama\ollama.exe"

# Check models (use full path)
& "$env:LOCALAPPDATA\Programs\Ollama\ollama.exe" list
```

### If you get "connection refused" error:
Ollama service might not be running. Start it:
```powershell
& "$env:LOCALAPPDATA\Programs\Ollama\ollama.exe" serve
```

(This runs in foreground. Stop with Ctrl+C when done.)

### If RAG Coach says "model not found":
The auto-detection should work, but if it doesn't, check backend logs for:
```
‚úÖ Found Ollama at: C:\Users\...\ollama.exe
‚úÖ Auto-detected Ollama model: mistral:7b-instruct-q4_k_m
```

## üìù Files You Can Use

1. **`auto_setup_rag_coach.py`** ‚≠ê - ONE-COMMAND SETUP
2. **`COMPLETE_SETUP_GUIDE.md`** - Step-by-step guide
3. **`verify_rag_coach_setup.py`** - Verification script
4. **`OLLAMA_INSTALLATION_GUIDE.md`** - Ollama details

## ‚ú® Summary

**You DON'T need to:**
- ‚ùå Manually add Ollama to PATH
- ‚ùå Configure model names
- ‚ùå Edit any configuration files
- ‚ùå Use `ollama` command directly

**Everything is automated:**
- ‚úÖ RAG Coach finds Ollama automatically
- ‚úÖ RAG Coach detects your model automatically
- ‚úÖ Just run the Python script or start the app
- ‚úÖ Everything works out of the box!

---

**Wait for download ‚Üí Run auto_setup script ‚Üí Start app ‚Üí Use RAG Coach!** üéâ
